{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estimation.analysis import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generic\\images\\midas\\streetview_id2_heading270.jpg\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'OSError' object has no attribute '__array_interface__'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     26\u001b[39m start = time.time()\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Uncommented desired estimation method\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Apply method 1.1 (MiDaS estimation with detectron2's pre-trained panoptic model)\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# sidewalk_w1, margin_w1 = analysis.estimate_width_m(img1_path,\"detectron2\",predictor,cfg,\"pavement\")\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     34\u001b[39m \n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Apply method 1.2 (MiDaS estimation with oneformers' pre-trained panoptic model)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m sidewalk_w2, margin_w2 = \u001b[43mestimate_width_m\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg1_path\u001b[49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moneformer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43moneformer_model_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshi-labs/oneformer_ade20k_swin_large\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43moneformer_label_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msidewalk, pavement\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m ela = time.time() - start\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMethod: MiDaS estimation\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mModel: Oneformer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDataset: ADE20k\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     41\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSidewalk width ~ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msidewalk_w2\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmargin_w2\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m meters\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mELA: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mela\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Users\\Juan\\sidewalk_analysis\\estimation\\analysis\\midas_estimation.py:44\u001b[39m, in \u001b[36mestimate_width_m\u001b[39m\u001b[34m(image_path, backend, detectron_predictor, detectron_cfg, detectron_label_name, oneformer_model_name, oneformer_label_name, device)\u001b[39m\n\u001b[32m     41\u001b[39m img_rgb = read_rgbimg(image_path)\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Obtain sidewalk_mask, cfg and img.read\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m sidewalk_mask, panoptic_seg, segments_info, detectron_cfg = \u001b[43msegment_sidewalk_mask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimg_rgb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdetectron_predictor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdetectron_predictor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdetectron_cfg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdetectron_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdetectron_label_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdetectron_label_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43moneformer_model_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43moneformer_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43moneformer_label_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43moneformer_label_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Initialize MiDaS for depth estimation\u001b[39;00m\n\u001b[32m     56\u001b[39m midas = torch.hub.load(\u001b[33m\"\u001b[39m\u001b[33mintel-isl/MiDaS\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDPT_Large\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Users\\Juan\\sidewalk_analysis\\utils\\segmentation.py:96\u001b[39m, in \u001b[36msegment_sidewalk_mask\u001b[39m\u001b[34m(img_rgb, backend, detectron_predictor, detectron_cfg, detectron_label_name, oneformer_model_name, oneformer_label_name, device)\u001b[39m\n\u001b[32m     93\u001b[39m     oneformer_processor = OneFormerProcessor.from_pretrained(oneformer_model_name)\n\u001b[32m     94\u001b[39m     oneformer_model = OneFormerForUniversalSegmentation.from_pretrained(\n\u001b[32m     95\u001b[39m         oneformer_model_name).to(device)\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     sidewalk_mask, panoptic_seg, segments_info = \u001b[43msegment_with_oneformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimg_rgb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moneformer_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moneformer_processor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moneformer_label_name\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown backend: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Users\\Juan\\sidewalk_analysis\\utils\\segmentation.py:42\u001b[39m, in \u001b[36msegment_with_oneformer\u001b[39m\u001b[34m(img_rgb, model, processor, device, label_name)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m image_pil = \u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_rgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m inputs = processor(images=image_pil, task_inputs=[\u001b[33m\"\u001b[39m\u001b[33mpanoptic\u001b[39m\u001b[33m\"\u001b[39m], return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m).to(device)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Juan Oliveira\\.conda\\envs\\detectron2_env\\Lib\\site-packages\\PIL\\Image.py:3300\u001b[39m, in \u001b[36mfromarray\u001b[39m\u001b[34m(obj, mode)\u001b[39m\n\u001b[32m   3253\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfromarray\u001b[39m(obj: SupportsArrayInterface, mode: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m) -> Image:\n\u001b[32m   3254\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3255\u001b[39m \u001b[33;03m    Creates an image memory from an object exporting the array interface\u001b[39;00m\n\u001b[32m   3256\u001b[39m \u001b[33;03m    (using the buffer protocol)::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3298\u001b[39m \u001b[33;03m    .. versionadded:: 1.1.6\u001b[39;00m\n\u001b[32m   3299\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3300\u001b[39m     arr = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__array_interface__\u001b[49m\n\u001b[32m   3301\u001b[39m     shape = arr[\u001b[33m\"\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   3302\u001b[39m     ndim = \u001b[38;5;28mlen\u001b[39m(shape)\n",
      "\u001b[31mAttributeError\u001b[39m: 'OSError' object has no attribute '__array_interface__'"
     ]
    }
   ],
   "source": [
    "# Uncomment these if you already have pre-defined your img1 and img2 paths\n",
    "img1_path = \"generic\\images\\midas\\streetview_id2_heading270.jpg\"\n",
    "img2_path = \"generic\\images\\streetview_3dtest_7.jpg\"\n",
    "\n",
    "model_path = \"Misc/panoptic_fpn_R_101_dconv_cascade_gn_3x.yaml\" \n",
    "# See available models at detectron2/configs - mind it must be panoptic\n",
    "\n",
    "# Download images - only if necessary\n",
    "'''\n",
    "# api = StreetViewAPI()\n",
    "\n",
    "# Method 1: Passing latitude and longitude\n",
    "# img1_path = api.download_image(lat=-23.6703243, lon=-46.5637054, fov=90, heading=256) # Replace params\n",
    "# img2_path = api.download_image(lat=None, lon=None) # Replace\n",
    "# img2 must be 5-20m from img1 and have same fov, pitch and heading\n",
    "\n",
    "# Method 2: Passing address\n",
    "# add = None # Add COMPLETE address as string\n",
    "# img1_path = api.download_image(address=None, fov=None, heading=None) # Replace params\n",
    "# img2_path = api.download_image(address=add)\n",
    "'''\n",
    "# Initialize detectron2's panoptic model - must be panoptic\n",
    "# predictor, cfg = initialize_model(model_path)\n",
    "\n",
    "# Capture initial time\n",
    "start = time.time()\n",
    "\n",
    "# Uncommented desired estimation method\n",
    "# Apply method 1.1 (MiDaS estimation with detectron2's pre-trained panoptic model)\n",
    "# sidewalk_w1, margin_w1 = analysis.estimate_width_m(img1_path,\"detectron2\",predictor,cfg,\"pavement\")\n",
    "# ela = time.time() - start\n",
    "# print(f\"Method: MiDaS estimation\\nModel: Detectron2\\nDataset: COCO\"\n",
    "#      f\"\\nSidewalk width ~ {sidewalk_w1:.2f} ± {margin_w1:.2f} meters\\nELA: {ela:.2f}s\")\n",
    "\n",
    "# Apply method 1.2 (MiDaS estimation with oneformers' pre-trained panoptic model)\n",
    "sidewalk_w2, margin_w2 = estimate_width_m(img1_path,\"oneformer\",\n",
    "oneformer_model_name=\"shi-labs/oneformer_ade20k_swin_large\",\n",
    "oneformer_label_name=\"sidewalk, pavement\")\n",
    "ela = time.time() - start\n",
    "print(f\"Method: MiDaS estimation\\nModel: Oneformer\\nDataset: ADE20k\"\n",
    "        f\"\\nSidewalk width ~ {sidewalk_w2:.2f} ± {margin_w2:.2f} meters\\nELA: {ela:.2f}s\")\n",
    "\n",
    "# Apply method 2.1 (3D reconstruction with detectron2's pre-trained panoptic model)\n",
    "# sidewalk_w3 = analysis.estimate_width_3dr(img1_path, img2_path, \"detectron2\", predictor, cfg, \"pavement\")\n",
    "# ela = time.time() - start\n",
    "# print(f\"Method: 3D reconstruction\\nModel: Detectron2\\nDataset: COCO\"\n",
    "#      f\"\\nSidewalk width ~ {sidewalk_w3:.2f} meters\\nELA: {ela:.2f}s\")\n",
    "\n",
    "# Apply method 2.2 (3D reconstruction with oneformer's pre-trained panoptic model)\n",
    "# sidewalk_w3 = analysis.estimate_width_3dr(img1_path, img2_path, \"oneformer\", \n",
    "# oneformer_model_name=\"shi-labs/oneformer_ade20k_swin_large\", \n",
    "# oneformer_label_name=\"sidewalk, pavement\")\n",
    "# ela = time.time() - start\n",
    "# print(f\"Method: 3D reconstruction\\nModel: Detectron2\\nDataset: ADE20k\"\n",
    "#      f\"\\nSidewalk width ~ {sidewalk_w3:.2f} meters\\nELA: {ela:.2f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
